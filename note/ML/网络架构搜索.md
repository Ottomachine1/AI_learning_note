9.3 网络架构搜索



本节课ppt：https://c.d2l.ai/stanford-cs329p/_static/pdfs/cs329p_slides_12_3.pdf



	这节课要看一下，具体到深度神经网络，怎么样通过算法来选取整个网络的架构



==========================================================================  



Neural Architecture Search (神经架构的搜索)：
![alt](https://i0.hdslb.com/bfs/note/1a740645f965b3d17ba68ade222112597673f465.png@1192w.avif)

00:16

神经网络有不同类型的超参数：如
网络的拓扑结构（ResNet、MobileNet(通过特殊的卷积层，把整个计算复杂度降低，使得在手机或其他低功耗设备上算的比较快)、架构的层数等）；
具体层的参数（卷积层中核窗口的大小、输出的通道数是多少、全连接层或RNN中输出的隐藏单元的个数）。
NAS的作用：尽量的使得整个网络的设计能够自动化
甚至可以从零开始设计一个神经网络；
给出一些网络的选择，选取最优的出来（有点像HPO）；
NAS需要关心的东西：
整个搜索的空间是什么样子的（整个神经网络的超参数【SGD的或是其他的超参数不关心】）；
怎么样在搜索空间中搜索；
怎么判断网络的好坏。
基本流程：设计一个搜索空间 -> 设计搜索策略 -> 每次采样一个架构出来，查看其性能 -> 反馈回搜索策略让策略更新；


==========================================================================  



早期NAS的工作：通过强化学习（Reinforcement Learning）
![alt](https://i0.hdslb.com/bfs/note/e94ff534724676811e6dbecc7bed61aa0b5062cc.png@1192w.avif)

02:53

主要思想：
将网络的超参数表示成文本；
用一个RNN（可以对一个时序序列建模）来生成不一样的整个网络架构；
生成一个之后对这个网络进行训练来算这个网络的验证精度；
将结果反馈给RNN网络；
然后RNN网络利用反馈回来的信息进行更新；
这个整个环用的就是RL(强化学习)【Agent做了一个行动，每行动一次就看下环境给出的反馈，通过反馈更新Agent】，好处：不管是什么套上RL之后可以在整个框架上显得比较优美的，坏处：十分昂贵；
课件上的参考资料：Neural Architecture Search with Reinforcement Learning(https://arxiv.org/abs/1611.01578)
最开始的工作用了 2000 GPU per days （10个GPU训练200天） 来做的，这样才能在一个小的数据集上得到一个不错的结果；后续有很多工作是帮最原始的工作加速的：在训练网络时不要跑完整个网络；或者是在建立架构的时候重用上一个网络的一些参数，不要从随机开始【相关工作：EAS,ENAS】；


==========================================================================  



One-shot 方法:

![alt](https://i0.hdslb.com/bfs/note/536c29b49e9910c704c3cb8edf2596e94c0f6c56.png@1192w.avif)
05:57

学习一个架构，既要学习整个网络的架构，也要学习模型里的超参数（训练一个特别大的模型，里面包含了想要看的模型的架构，然后将这个模型训练一遍，里面的子模型就是我们要考虑的架构，这样既能得到他的性能又可以得到他的参数）
然而上面的方法很昂贵，甚至可能 不能放入GPU的内存中，一般来说很难将网络训练的收敛；
一般的做法是只关心候选架构的排名（两个架构相互比较判断其好坏，不需要知道他的精度是多少），所以可以用一个近似的指标，在训练一些轮次之后看一下精度就好了，然后把好的架构挑出来（不需要是最好的）从头开始完整的训练一遍


==========================================================================  



可微的结构搜索（Differentiable Architecture Search）：
![alt](https://i0.hdslb.com/bfs/note/fd666f91cb02a6792acdaf6e139ccd347ee6e503.png@1192w.avif)

08:01

训练一个很大的模型，具体取一条子图可能会比较难选，我们可以通过把选谁做成一个可以学习的参数；具体来说，是通过softMax 的操作来进行子路的选择；
具体看图：08:31
这个方法也就是通过学习来选择哪条路比较好，这样子可以避免要不断去看哪条路是最好的；
对这个方法的改进，可以对softmax 加上一个温度使得它更能趋向于0或1，而不是再0与1的中间值徘徊；
如一个更复杂的版本，DARTS，基本上使用三个GPU训练一天能训练到一个不错的精度


==========================================================================  



缩放CNN：
![alt](https://i0.hdslb.com/bfs/note/27ff51b69d6ee6a2d9e6806b9c795421404c3c50.png@1192w.avif)

13:12

EfficientNet就是用这个的方法搜出来的；这个方法有局限性：只对于一小部分的神经网络使用
卷积神经网络可以通过三种方法来调节：
深度：可以加更多层进去，可以将层数乘上个系数翻倍；
宽度（卷积层输出的通道）：让输出通道翻倍
大的输入：将输入的图片弄大一点；
EfficientNet是说，尽量不去动任何一个东西，你要三个东西一起动，具体的来说：
有四个可调的参数 α β γ φ；
深度可以变换 α的φ次方倍；宽度就是变换 β的φ次方倍；图片大小（分辨率）就是变换γ的φ次方倍；这些都要取整；
α β γ 是要选择 α * β^2 * γ^2 ≈ 2 （因为整个神经网络的计算复杂度是深度 * 宽度^2 * 输出数据的高宽^2 ），但φ取1时，整个CNN的计算复杂度就会翻一倍；
α β γ 是会手动调好的，最后只需调φ这个值，通过调整这个来放大或缩小计算复杂度；
从图看效果：

17:54



==========================================================================  



最近的研究方向的重点：

![alt](https://i0.hdslb.com/bfs/note/fe21d2fc2a8ac04f1d97fec05a725cc7b79e1df8.png@1192w.avif)
18:26

搜出来的结果是否能解释：EfficientNet搜出来的还好一点，之前的搜出来的网络架构会没那么对称，不那么模块化，参数也很奇怪；
跟人去比较，意义不大；但是NAS一个不错的应用场景是在边缘设备上（手机等）
手机是越来越强了，神经网络可以跑在手机上；
神经网络跑在手机上，这样延迟会低，数据隐私会比较好（数据放在手机上，不用送去服务器）；
边缘设备的计算性能是要考虑的点（高低端的手机CPU/GPU/DSP(数字处理信号单元)的差距比较大）；功耗也是需要考虑的点；
在不同的设备，功耗有限制的情况下，要如何设计网络架构：对不同的手机，去自动调一个网络让在模型在手机上保证延迟和功耗的效果也不错【选一个网络架构，然后去看它验证集损失 乘以 这个网络在该设备上跑一遍的延迟的log的β次方；这个是可以调的，看看是更关注延迟还是更关注精度】
更大的研究方向是说让整个机器学习的流程更加自动化;


==========================================================================  



总结：
![alt](https://i0.hdslb.com/bfs/note/12addd2b3681b510631f027aee076888c3f85a8a.png@1192w.avif)

22:41

NAS是搜索一个神经网络架构，可以有一个定制化的目标（最大化精度，或者满足对延迟的需求），可以在特定的硬件上；
NAS现在用的还算比较多的，上面讲到的在CNN中可以将深度，宽度和输入的分辨率合起来调，基本上是调一个超参数就可以得到我们想要的不同精度下和不同性能下的各个不错的组合
可以使用可导的one-hot 网络来训练一个特别大的架构，里面包含了我们想要的超参数，然后通过一个softmax操作，让他去学习一个权重来决定哪一条路最好；
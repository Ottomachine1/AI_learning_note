5.1 方差和偏差

本节课ppt:https://c.d2l.ai/stanford-cs329p/_static/pdfs/cs329p_slides_7_1.pdf





统计学习中的重要指标——方差偏差

![alt](https://i0.hdslb.com/bfs/note/c768a4b72006b781b44dd7ff853c1021fd58ea3b.png@1192w.avif)
00:11

在统计学习中我们通常会使用方差和偏差来衡量一个模型，
偏差：训练到的模型与真实模型之间的区别（图中蓝点与加号之间的距离）；
方差：每次学习的模型之间差别有多大；
图中【中间的加号指的是我们要学的真实模型的地方，圆圈是可容忍的区域，蓝色的圆指的是训练的模型得出的结果，蓝色的点的个数代表了所训练模型的个数】
如果所有训练的模型都在大圆内 且 与加号离得很近的话，我们可以认为模型有低偏差和低方差；
如果所有训练的模型没有在大圆内，那么可以说它的偏差很大；但是每一个蓝点之间差别没有那么大，就表示说方差是比较小的；
虽然每个蓝点基本都落到了大圆中，但是每个蓝点的距离比较大；这样偏差比较低，但是方差很大；
最差的一个情况是：每个蓝点既不落在大圆内且每次训练的不一样（之间的距离很大）；即方差和偏差都是很大的
我们需要的是低偏差和低方差，这样会是比较好的模型，若出现其他三种情况的话，要考虑用其他方法使得方差和偏差都降低；


==========================================================================



偏差和方差在数学上的定义：


![alt](https://i0.hdslb.com/bfs/note/8a876b430bcfd3a21cdb6cd4c11603c69d54b181.png@1192w.avif)


03:00

假设每次采样都是从有噪声ε的函数f(x)中采样数据用于学习f_hat
通过学习使得f_hat与 真实的f 尽可能的相近（这是个回归问题可以用最小MSE（均方误差）来实现）
我们学习到之后需要通过 泛化误差 来衡量它；在统计学习中，我们想通过学习来使得模型能泛化到没有学习过的样本，所以我们需要优先优化 [y-f(x)_hat]^2 的期望值 = 偏差^2 + 方差 +噪声^2




对公式的解释(ref: 西瓜书p45)：04:35



==========================================================================



从图来说明：

![alt](https://i0.hdslb.com/bfs/note/fc00829d07c509de2579034ba3232e91fe5d9910.png@1192w.avif)
10:26

刚开始模型过于简单可能学不到真实数据所要表达的内容，这时的偏差的平方会很大，随着模型的逐渐复杂，模型可能可以学到所想表达的信息，所以偏差的平方逐渐变小；
随着模型变得越来越复杂，能够拟合的东西就越大，这样模型可能会过多的关注于噪音（数据还是那些数据 数据复杂度低），所以方差会变得越来越大；
泛化误差 = 数据本身的噪音，但是数据本身没有变化，应该是个常数；但是加上了偏差和方差，最后就会导致最后的泛化误差曲线就会跟图中的蓝线一样
跟之前讲过的下图有关，
![alt](https://i0.hdslb.com/bfs/note/2481c792361e79500d1835d57ee06017379dcf4b.png@1020w_608h.avif)
训练误差往往会跟偏差相关（偏差越小，模型就越容易拟合到数据上）；图上两条线的差距可以说是方差在起作用；



==========================================================================



减小偏差、方差、噪声：

![alt](https://i0.hdslb.com/bfs/note/7c3a5fa894e1cc5a2234fda822722414f17b85ad.png@1192w.avif)
13:30

我的任务是减小泛化误差，那我们需要减小偏差、方差、噪声
减小偏差：偏差很大，说明模型复杂度可能不够，可以使用一个模型复杂度高一点的模型（在神经网络中可以 增加层数 增加隐藏层单元个数（宽度））；也可使用【Boosting；Stacking】
减小方差：方差太大可能代表你的模型过于复杂，我们可以是用一个简单点的模型，或者是使用正则化（使用L2，L1正则项，限制住每个模型能够学习的范围）；也可使用【Bagging；Stacking】
降低噪声：在统计学习中，这个是不可以降低的误差，但是在真实的场景，这是来自于数据采集，可以通过更精确的数据采集，更干净的数据来使得噪声降低
集成学习：使用多个模型来提升性能【上面提到的Boosting；Stacking；Bagging； 后面的小节会说】


==========================================================================



总结：

![alt](https://i0.hdslb.com/bfs/note/e965be9375e3d98940325c7510ceac0159e502d2.png@1192w.avif)
16:26

在统计学习中，我们可以把泛化误差分解为 偏差、误差和噪声三项；
集成学习能够将多个模型组合起来来降低偏差和方差
